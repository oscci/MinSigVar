
@misc{rcoreteam2020,
	title = {R: {A} language and environment for statistical computing.},
	url = {https://www.R-project.org/},
	publisher = {R Foundation for Statistical Computing, Vienna, Austria},
	author = {R Core Team,},
	year = {2020},
}

@Manual{champely2020,
    title = {pwr: Basic Functions for Power Analysis},
    author = {Stephane Champely},
    year = {2020},
    note = {R package version 1.3-0},
    url = {https://CRAN.R-project.org/package=pwr},
  }

@article{moher2010,
	title = {{CONSORT} 2010 explanation and elaboration: updated guidelines for reporting parallel group randomised trials},
	volume = {340},
	issn = {1756-1833},
	shorttitle = {{CONSORT} 2010 explanation and elaboration},
	doi = {10.1136/bmj.c869},
	language = {eng},
	journal = {BMJ (Clinical research ed.)},
	author = {Moher, David and Hopewell, Sally and Schulz, Kenneth F. and Montori, Victor and GÃ¸tzsche, Peter C. and Devereaux, P. J. and Elbourne, Diana and Egger, Matthias and Altman, Douglas G.},
	month = mar,
	year = {2010},
	pmid = {20332511},
	pmcid = {PMC2844943},
	keywords = {Randomized Controlled Trials as Topic, Research Design, Consensus, Practice Guidelines as Topic},
	pages = {c869},
	file = {Full Text:/Users/dorothybishop/Zotero/storage/G2GQ8TCK/Moher et al. - 2010 - CONSORT 2010 explanation and elaboration updated .pdf:application/pdf},
}

@article{lazic2021,
	title = {Why multiple hypothesis test corrections provide poor control of false positives in the real world},
	url = {http://arxiv.org/abs/2108.04752},
	abstract = {Most scientific disciplines use significance testing to draw conclusions from experimental or observational data. This classical approach provides theoretical guarantees for controlling the number of false positives across a set of hypothesis tests, making it an appealing framework for scientists who wish to limit the number of false effects or associations that they claim exist. Unfortunately, these theoretical guarantees apply to few experiments and the actual false positive rate (FPR) is much higher than the theoretical rate. In real experiments, hypotheses are often tested after finding unexpected relationships or patterns, the data are analysed in several ways, analyses may be run repeatedly as data accumulate from new experimental runs, and publicly available data are analysed by many groups. In addition, the freedom scientists have to choose the error rate to control, the collection of tests to include in the adjustment, and the method of correction provides too much flexibility for strong error control. Even worse, methods known to provide poor control of the FPR such as Newman-Keuls and Fisher's Least Significant Difference are popular with researchers. As a result, adjusted p-values are too small, the incorrect conclusion is often reached, and reported results are less reproducible. Here, I show why the FPR is rarely controlled in any meaningful way and argue that a single well-defined FPR does not even exist.},
	urldate = {2021-08-12},
	journal = {arXiv:2108.04752 [q-bio, stat]},
	author = {Lazic, Stanley E.},
	month = aug,
	year = {2021},
	note = {arXiv: 2108.04752},
	keywords = {Quantitative Biology - Quantitative Methods, Statistics - Applications},
	file = {arXiv Fulltext PDF:/Users/dorothybishop/Zotero/storage/5UUUW7C9/Lazic - 2021 - Why multiple hypothesis test corrections provide p.pdf:application/pdf;arXiv.org Snapshot:/Users/dorothybishop/Zotero/storage/LEYT9Z35/2108.html:text/html},
}
